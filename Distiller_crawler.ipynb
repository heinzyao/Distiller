{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import time\n",
    "import math\n",
    "import threading\n",
    "import logging\n",
    "\n",
    "from tqdm import trange, tqdm\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import csv\n",
    "import json\n",
    "import pprint\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting log\n",
    "\n",
    "logging_format = '%(asctime)s : %(message)s'\n",
    "logging.basicConfig(level=logging.INFO, format=logging_format, filename='myLog.log', filemode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing for Crawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_2) AppleWebKit/537.36 (KHTML, like Gecko)\\\n",
    "                    Chrome/79.0.3945.88 Safari/537.36\",\n",
    "        \"Connection\": \"keep-alive\",\n",
    "        \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8\",\n",
    "        \"Accept-Language\": \"en-US,en;q=0.8\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166\n"
     ]
    }
   ],
   "source": [
    "#Getting the number of pages\n",
    "\n",
    "html = requests.get('https://distiller.com/search?official_status=official', headers = my_headers)\n",
    "bsObj = BeautifulSoup(html.text)\n",
    "\n",
    "page_count = math.ceil(int(bsObj.find('span', \n",
    "{'class':'pagination-control__description'}).getText().strip().split(' ')[-2]) / 50) \n",
    "\n",
    "print(page_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link Crawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://distiller.com/search?official_status=official&page='\n",
    "url_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUrls(url):\n",
    "\n",
    "    num = 1\n",
    "\n",
    "    for page in trange(num, page_count+1):\n",
    "        \n",
    "        try:    \n",
    "            html = requests.get(url + str(page))\n",
    "            bsObj = BeautifulSoup(html.text)\n",
    "\n",
    "            for link in bsObj.findAll('a', href = re.compile('^(/spirits/)')):\n",
    "                if 'href' in link.attrs:\n",
    "                    \n",
    "                    #lock.acquire()\n",
    "                    url_list.append('https://distiller.com{}'.format(link.attrs['href']))\n",
    "                    #lock.release()\n",
    "            \n",
    "            logging.info('Parsed {} of {} pages'.format(num, page_count))\n",
    "            \n",
    "            #print('Parsed {} of {} pages'.format(num, page_count))\n",
    "        \n",
    "            num += 1\n",
    "            #if num % 25 == 0:\n",
    "            #    clear_output()\n",
    "\n",
    "            time.sleep(1)\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.exception(e)\n",
    "            print(e)\n",
    "            continue \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 166/166 [05:51<00:00,  2.12s/it]\n"
     ]
    }
   ],
   "source": [
    "getUrls(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8297 links saved\n"
     ]
    }
   ],
   "source": [
    "url_list = list(set(url_list))\n",
    "logging.info('{} links saved'.format(len(url_list)))\n",
    "print('{} links saved'.format(len(url_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://distiller.com/spirits/appleton-special-white-rum']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_url_list = list([i] for i in url_list)\n",
    "new_url_list[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://distiller.com/spirits/wheatley-vodka'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outputing links as csv\n",
    "with open('links.csv','w', newline ='') as file:\n",
    "\n",
    "    writer = csv.writer(file, delimiter=',')\n",
    "    writer.writerow(['url'])\n",
    "    writer.writerows(new_url_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Crawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "exec_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing links from csv\n",
    "url_list = []\n",
    "\n",
    "with open('links.csv','r', newline ='') as file:\n",
    "    rows = csv.reader(file)\n",
    "    for row in rows:\n",
    "        url_list.append(row[0])\n",
    "        \n",
    "url_list.remove('url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(start=0, end=-1):    \n",
    "    \n",
    "    global exec_count\n",
    "    global data\n",
    "\n",
    "    for url in tqdm(url_list[start:end]):   \n",
    "        \n",
    "        while True:\n",
    "            try:            \n",
    "                spirit_info = {   \n",
    "                    'name':'',\n",
    "                    'type':'',\n",
    "                    'brand_name':'',\n",
    "                    'origin':'',\n",
    "                    'cost_level':0,\n",
    "                    'age':0,\n",
    "                    'abv':0,\n",
    "                    'expert_rating':0,\n",
    "                    'average_user_rating':0,\n",
    "                    'user_comments':0,\n",
    "                    'description':'',\n",
    "                    'tasting_notes':'',\n",
    "                    'reviewer':'',\n",
    "                    'flavor_profile':'',\n",
    "                      }\n",
    "\n",
    "                html = requests.get(url)\n",
    "                bsObj = BeautifulSoup(html.text)\n",
    "\n",
    "                #name\n",
    "                spirit_info['name'] = bsObj.find('h1', {'itemprop':'name'}).string.strip()\n",
    "\n",
    "                #type\n",
    "                spirit_info['type'] = bsObj.find('h2', \n",
    "                    {'class':'ultra-mini-headline type'}).string.strip()\n",
    "\n",
    "                #brand-name\n",
    "                try:\n",
    "                    spirit_info['brand_name'] = bsObj.find('h2', \n",
    "                        {'itemprop':'brand_name'}).string.strip().split(' // ')[0]\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                #origin\n",
    "                try:\n",
    "                    spirit_info['origin'] = bsObj.find('h2', \n",
    "                        {'itemprop':'brand_name'}).string.strip().split(' // ')[1]\n",
    "                except:\n",
    "                    spirit_info['origin'] = bsObj.find('h2', {'itemprop':'brand_name'}).string.strip()\n",
    "\n",
    "\n",
    "                #cost-level\n",
    "                cost_index = str(bsObj.find('div', {'class':'value'})).index('cost-')+5\n",
    "                spirit_info['cost_level'] = int(str(bsObj.find('div', {'class':'value'}))[cost_index])\n",
    "\n",
    "                #age\n",
    "                try:\n",
    "                    spirit_info['age'] = int(bsObj.find('li', \n",
    "                        class_='detail age').getText().strip().split(' ')[-1])\n",
    "                except:\n",
    "                    spirit_info['age'] = None\n",
    "\n",
    "                #abv\n",
    "                abv = bsObj.find('li', class_='detail abv').getText()[5:].strip()\n",
    "\n",
    "                if abv.isnumeric():\n",
    "\n",
    "                    try:\n",
    "                        spirit_info['abv'] = float(abv)\n",
    "                    except:\n",
    "                        spirit_info['abv'] = int(abv)\n",
    "\n",
    "                else:\n",
    "                    try:\n",
    "                        spirit_info['abv'] = abv\n",
    "                    except:\n",
    "                        spirit_info['abv'] = None\n",
    "\n",
    "                #expert-rating\n",
    "                try:\n",
    "                    rating_index = str(bsObj.find('span', {'class':'expert-rating'})).index('>')+2\n",
    "                    spirit_info['expert_rating'] = int(str(bsObj.find('span', \n",
    "                            {'class':'expert-rating'}))[rating_index:rating_index+2])\n",
    "\n",
    "                except: \n",
    "                    spirit_info['expert_rating'] = None\n",
    "\n",
    "                #average-user-rating\n",
    "                try: \n",
    "                    spirit_info['average_user_rating'] = round(float(bsObj.find('span', \n",
    "                        {'itemprop':'ratingValue'}).string)*20, 2)\n",
    "                except:\n",
    "                    spirit_info['average_user_rating'] = None\n",
    "\n",
    "                #user-comments\n",
    "                try: \n",
    "                    spirit_info['user_comments'] = int(bsObj.find(('a','span'), {'class':'count'}).string)\n",
    "                except:\n",
    "                    spirit_info['average_user_rating'] = None\n",
    "\n",
    "                #description\n",
    "                try:\n",
    "                    spirit_info['description'] = bsObj.find('p', {'itemprop':'description'}).string\n",
    "                except:\n",
    "                    spirit_info['description'] = None\n",
    "\n",
    "                #tasting-notes\n",
    "                try:\n",
    "                    spirit_info['tasting_notes'] = bsObj.find('p', {'itemprop':'reviewBody'}).string.strip('\"')\n",
    "                except:\n",
    "                    spirit_info['tasting_notes'] = None\n",
    "\n",
    "                #reviwer\n",
    "                try:\n",
    "                    spirit_info['reviewer'] = bsObj.find('a', {'itemprop':'author'}).string.strip()\n",
    "                except:\n",
    "                    spirit_info['reviewer'] = None\n",
    "\n",
    "                #flavor-profile          \n",
    "                try:\n",
    "                    flavor_data = str(bsObj.find('canvas',{'class':['js-flavor-profile-chart']}))\n",
    "                    flavor_data_list = []\n",
    "\n",
    "                    raw_text = flavor_data.split('{')[1].split('}')[0]\n",
    "                    #print(raw_text)\n",
    "\n",
    "                    word = ''\n",
    "\n",
    "                    for letter in raw_text:\n",
    "\n",
    "                        if letter.isalpha() and letter != '_':\n",
    "                            word += letter\n",
    "\n",
    "                        elif letter == '_':\n",
    "                            word += letter\n",
    "\n",
    "                        elif letter.isnumeric():\n",
    "                            word += letter\n",
    "\n",
    "                        else:\n",
    "                            flavor_data_list.append(word)\n",
    "                            word = ''\n",
    "\n",
    "                    if flavor_data_list[-1] == '':\n",
    "                        flavor_data_list.append(raw_text[-2:])\n",
    "\n",
    "                    #print(flavor_data_list) \n",
    "\n",
    "                    flavors = []\n",
    "\n",
    "                    for item in flavor_data_list:\n",
    "                        if item != '':\n",
    "                            flavors.append(item)\n",
    "\n",
    "                    #print(flavors)\n",
    "\n",
    "                    ## Save as dict\n",
    "                    flavor_profile = dict(zip((i for i in flavors[0::2]), (int(i.strip()) for i in flavors[1::2])))        \n",
    "                    spirit_info['flavor_profile'] = flavor_profile\n",
    "\n",
    "                except:\n",
    "                    spirit_info['flavor_profile'] = None\n",
    "\n",
    "                #Add to a list      \n",
    "                time.sleep(3)\n",
    "\n",
    "                lock = threading.Lock()            \n",
    "                lock.acquire()\n",
    "\n",
    "                data.append(spirit_info)\n",
    "                exec_count += 1\n",
    "\n",
    "                lock.release()\n",
    "\n",
    "                if  exec_count % 10 == 0:\n",
    "                    clear_output()\n",
    "\n",
    "                logging.info('Parsed {} of {} links'.format(exec_count , len(url_list)))\n",
    "                #print('Parsed {} of {} links'.format(exec_count , len(url_list)))\n",
    "                \n",
    "                break\n",
    "\n",
    "            except Exception as e:\n",
    "                logging.exception(e)\n",
    "                print(e)\n",
    "                time.sleep(30)\n",
    "                continue\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 827, 1654, 2481, 3308, 4135, 4962, 5789, 6616, 7443, 8271]\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "#Dividing the urls into segments\n",
    "\n",
    "seg = 10\n",
    "seg_list=[]\n",
    "\n",
    "for i in range(seg):\n",
    "    seg_list.append(int(len(url_list)/seg*i))\n",
    "\n",
    "seg_list.append(len(url_list))\n",
    "\n",
    "print(seg_list)\n",
    "print(len(seg_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #test\n",
    "# data = []\n",
    "# exec_count = 0\n",
    "\n",
    "# main(0, 8118)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 827/827 [1:16:19<00:00,  5.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "threads = []\n",
    "num = len(seg_list)\n",
    "\n",
    "for i in range(0, num-1):\n",
    "    threads.append(threading.Thread(target = main, args = (seg_list[i], seg_list[i+1])))\n",
    "    threads[i].start()\n",
    "\n",
    "# 等待所有子執行緒結束\n",
    "for index in range(0, num-1):\n",
    "    threads[index].join()\n",
    "\n",
    "logging.info(\"Done\")\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8271 <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(len(data), type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \n",
      " Old Bones Bourbon 10 Year Reserve \n",
      "\n",
      "type: \n",
      " Bourbon \n",
      "\n",
      "brand_name: \n",
      " Backbone Bourbon \n",
      "\n",
      "origin: \n",
      " Indiana (Bottled in Kentucky), USA \n",
      "\n",
      "cost_level: \n",
      " 4 \n",
      "\n",
      "age: \n",
      " None \n",
      "\n",
      "abv: \n",
      " 55.0 \n",
      "\n",
      "expert_rating: \n",
      " None \n",
      "\n",
      "average_user_rating: \n",
      " 72.2 \n",
      "\n",
      "user_comments: \n",
      " 20 \n",
      "\n",
      "description: \n",
      " This limited release, high-rye bourbon from Backbone Bourbon Company was distilled in Lawrenceburg, Indiana (MGP-sourced) from a mash bill of 55% corn, 40% rye, and 5% barley. Old Bones Bourbon 10 Year Reserve was bottled in Bardstown, Kentucky at a high proof of 55% ABV, after aging a decade in new, charred American oak barrels. \n",
      "\n",
      "tasting_notes: \n",
      " None \n",
      "\n",
      "reviewer: \n",
      " None \n",
      "\n",
      "flavor_profile: \n",
      " None \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key in data[-1]:\n",
    "    print('{}: \\n {} \\n'.format(key, data[-1][key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['name', 'type', 'brand_name', 'origin', 'cost_level', 'age', 'abv', 'expert_rating', 'average_user_rating', 'user_comments', 'description', 'tasting_notes', 'reviewer', 'flavor_profile']\n"
     ]
    }
   ],
   "source": [
    "fieldnames = list(data[0].keys())\n",
    "print(fieldnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output as csv\n",
    "\n",
    "with open(f'distiller_{date[0]+date[1]+date[2]}.csv','w', newline ='') as file:\n",
    "    \n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)   \n",
    "    \n",
    "    writer.writeheader()\n",
    "    \n",
    "    for item in data:\n",
    "        writer.writerow(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting as JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to JSON\n",
    "json_data = json.dumps(data, sort_keys=True, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20200330\n"
     ]
    }
   ],
   "source": [
    "date = \"\".join(time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()).split(' ')[0].split('-'))\n",
    "print(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output as JSON\n",
    "with open(f'distiller_{date}.json','w') as file:\n",
    "    file.write(json_data)"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
